{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT2020038_MT2020069_NLP_Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abdad9397fe342c881f3326133586b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4fa26d7460747a2b776cef6d3e05319",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed8a4193ed044238bc8fac21ce524962",
              "IPY_MODEL_7b084906c5c64763b0f6be9880fbc41f"
            ]
          }
        },
        "f4fa26d7460747a2b776cef6d3e05319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed8a4193ed044238bc8fac21ce524962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8e1efe71b16f419a8fe21370de638332",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_173e94a6727e47a69a547d556ec435d8"
          }
        },
        "7b084906c5c64763b0f6be9880fbc41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f672f6ff2d094a01914f53dcba368659",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 759kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3a22fd324d8439ebf1d35e3e669a205"
          }
        },
        "8e1efe71b16f419a8fe21370de638332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "173e94a6727e47a69a547d556ec435d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f672f6ff2d094a01914f53dcba368659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3a22fd324d8439ebf1d35e3e669a205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d322eddf22ac4b7181334df17d9b7721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5547aaa8122341b4a8bc269095cb7503",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_87f4b414439f4f7ea48e9163c5083929",
              "IPY_MODEL_04902f1363e44fcd843473a16042223c"
            ]
          }
        },
        "5547aaa8122341b4a8bc269095cb7503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87f4b414439f4f7ea48e9163c5083929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ff1fceee0fe4f7594c4b76d91592f24",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f679382fda674304a47a18771aa25a66"
          }
        },
        "04902f1363e44fcd843473a16042223c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84859d3106564496b69e7e1cc0fb668a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 298B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99b438cd4fbb4515a870d71ebc9758fd"
          }
        },
        "4ff1fceee0fe4f7594c4b76d91592f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f679382fda674304a47a18771aa25a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84859d3106564496b69e7e1cc0fb668a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99b438cd4fbb4515a870d71ebc9758fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b0f5c342db340df947b566cda487c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb6d950fb3cb4c4eb71c7f2969adeeb8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1bbc07e579ef4768aab8affa53436c5f",
              "IPY_MODEL_1511d11cc9464f0b94a50773bae0c320"
            ]
          }
        },
        "fb6d950fb3cb4c4eb71c7f2969adeeb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bbc07e579ef4768aab8affa53436c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ede23482ba4e495fbed511e92cea10d7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08385086c0b44a70903a6b767f110c34"
          }
        },
        "1511d11cc9464f0b94a50773bae0c320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4946afc0f789418dabab4ca1a9b70c8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 5.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b980c49e7ed41c796e9badc4a38d8e8"
          }
        },
        "ede23482ba4e495fbed511e92cea10d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08385086c0b44a70903a6b767f110c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4946afc0f789418dabab4ca1a9b70c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b980c49e7ed41c796e9badc4a38d8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d58909ec818e43b7ac68b782908831ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8240d92612664f34a41d2ef22b902ae4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ade15b632c734065a8ee81af0f061d2c",
              "IPY_MODEL_540f7c56aaaa49969334476aee76a63f"
            ]
          }
        },
        "8240d92612664f34a41d2ef22b902ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ade15b632c734065a8ee81af0f061d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ce6a9cb19fe4697abe5dbf843c64640",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d92b795696d54e569152af52b8b9ea21"
          }
        },
        "540f7c56aaaa49969334476aee76a63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b73b344e1b5a425cb44c849470dab50a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [02:22&lt;00:00, 3.99B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_563785ff2d3e40bfbb1ed0b01b52cda7"
          }
        },
        "1ce6a9cb19fe4697abe5dbf843c64640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d92b795696d54e569152af52b8b9ea21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b73b344e1b5a425cb44c849470dab50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "563785ff2d3e40bfbb1ed0b01b52cda7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55f5f6c28b2b4516a90b98f3579bd5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08d2d0a690324eadb5c87b1e1f53ceea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e3f4b0858294143819eb9892ed3bf9d",
              "IPY_MODEL_1f2b704a16da42ac8a3aa10dcb870933"
            ]
          }
        },
        "08d2d0a690324eadb5c87b1e1f53ceea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e3f4b0858294143819eb9892ed3bf9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6f5e4c6e9f04e5780777486d4a6b794",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fb28545a25e47a3b989c0225c6cd9a4"
          }
        },
        "1f2b704a16da42ac8a3aa10dcb870933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_238130fdb0ad40d0961df55b3e4321b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 49.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e88dab3c732747649aa711e526c9b32b"
          }
        },
        "c6f5e4c6e9f04e5780777486d4a6b794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fb28545a25e47a3b989c0225c6cd9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "238130fdb0ad40d0961df55b3e4321b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e88dab3c732747649aa711e526c9b32b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZZwqmBbGu4G"
      },
      "source": [
        "# Assessing the Funniness of Edited News Headlines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ_eJlpiv1uQ"
      },
      "source": [
        "# Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDrEqP3W2WC2",
        "outputId": "6525351c-8620-467f-fa8a-3538a5452c47"
      },
      "source": [
        "# Installing HuggingFace transformers library\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 24.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: huggingface-hub, sacremoses, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amgNcHhMuRz3"
      },
      "source": [
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RcRFTVTz-on"
      },
      "source": [
        "# To see complete text in the dataframe\n",
        "pd.set_option(\"display.max_colwidth\", -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRT92wk0v_aM"
      },
      "source": [
        "# Data Collection and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJGXXcvt7DYc"
      },
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HnbY-Dpvqfx",
        "outputId": "4e61084c-4e3f-4c72-c9ab-64e4e1515905"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk1xVB3BvwOK"
      },
      "source": [
        "train_set = pd.read_csv(\"/content/drive/My Drive/DataSets/subtask-1/train.csv\")\n",
        "valid_set = pd.read_csv(\"/content/drive/My Drive/DataSets/subtask-1/dev.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WNZ4-yL7Gkd"
      },
      "source": [
        "## Visualization and Normal Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "y4D3sezpwn8F",
        "outputId": "8143a49f-5ff0-49e3-a51d-fac9b1491ae7"
      },
      "source": [
        "train_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined &lt;Isis/&gt; â€™ without trial in Iraq</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after &lt;Syria/&gt; strikes . What does that mean ?</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes &lt;Coalition/&gt;</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage/&gt; each other militarily</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vice/&gt; President .</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9647</th>\n",
              "      <td>10899</td>\n",
              "      <td>State officials blast ' unprecedented ' DHS &lt;move/&gt; to secure electoral system</td>\n",
              "      <td>idea</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9648</th>\n",
              "      <td>1781</td>\n",
              "      <td>Protesters Rally for &lt;Refugees/&gt; Detained at JFK Airport After Trump Ban</td>\n",
              "      <td>stewardesses</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9649</th>\n",
              "      <td>5628</td>\n",
              "      <td>Cruise line Carnival Corp. joins the fight against Bermuda 's same-sex &lt;marriage/&gt; ban</td>\n",
              "      <td>raisin</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9650</th>\n",
              "      <td>14483</td>\n",
              "      <td>Columbia police hunt woman seen with &lt;gun/&gt; near University of Missouri campus</td>\n",
              "      <td>cake</td>\n",
              "      <td>32200</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9651</th>\n",
              "      <td>5255</td>\n",
              "      <td>Here 's What 's In The House-Approved Health &lt;Care/&gt; Bill</td>\n",
              "      <td>food</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9652 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... meanGrade\n",
              "0     14530  ...  0.2     \n",
              "1     13034  ...  1.6     \n",
              "2     8731   ...  1.0     \n",
              "3     76     ...  0.4     \n",
              "4     6164   ...  0.0     \n",
              "...    ...   ...  ...     \n",
              "9647  10899  ...  0.0     \n",
              "9648  1781   ...  0.4     \n",
              "9649  5628   ...  0.6     \n",
              "9650  14483  ...  1.4     \n",
              "9651  5255   ...  0.4     \n",
              "\n",
              "[9652 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "xyabfQ-Jwph-",
        "outputId": "d474485f-2b4a-4506-87a8-973b20804c38"
      },
      "source": [
        "valid_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted of long-abolished sexual offences are posthumously pardoned</td>\n",
              "      <td>swans</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12736</td>\n",
              "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
              "      <td>chef</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12274</td>\n",
              "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror &lt;suspects/&gt;</td>\n",
              "      <td>squad</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8823</td>\n",
              "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ' unfounded rumor ' about Melania Trump</td>\n",
              "      <td>applauds</td>\n",
              "      <td>32210</td>\n",
              "      <td>1.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5087</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Russian &lt;Missile/&gt; striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .</td>\n",
              "      <td>balloon</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>1202</td>\n",
              "      <td>Supreme &lt;Court/&gt; Once Again Strikes Down Racial Gerrymandering In North Carolina</td>\n",
              "      <td>leaders</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2415</th>\n",
              "      <td>14764</td>\n",
              "      <td>Trump Mocks Schumer â€™s Tears ; Vows to â€˜ Make America &lt;Safe/&gt; Again â€™</td>\n",
              "      <td>Insane</td>\n",
              "      <td>33333</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>12595</td>\n",
              "      <td>US government memo on the &lt;danger/&gt; of leaking to media has been leaked</td>\n",
              "      <td>amusement</td>\n",
              "      <td>22111</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2417</th>\n",
              "      <td>70</td>\n",
              "      <td>Newt Gingrich : Join Me in Supporting Judge Roy Moore to &lt;Advance/&gt; the President â€™s Agenda</td>\n",
              "      <td>Molest</td>\n",
              "      <td>32110</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2418</th>\n",
              "      <td>14315</td>\n",
              "      <td>In Search of Donald Trump at His Boyhood &lt;Home/&gt;</td>\n",
              "      <td>Castle</td>\n",
              "      <td>11100</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2419 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... meanGrade\n",
              "0     1723   ...  1.0     \n",
              "1     12736  ...  0.8     \n",
              "2     12274  ...  0.6     \n",
              "3     8823   ...  1.6     \n",
              "4     5087   ...  0.4     \n",
              "...    ...   ...  ...     \n",
              "2414  1202   ...  0.2     \n",
              "2415  14764  ...  3.0     \n",
              "2416  12595  ...  1.4     \n",
              "2417  70     ...  1.4     \n",
              "2418  14315  ...  0.6     \n",
              "\n",
              "[2419 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DpxZ9UDwtJm"
      },
      "source": [
        "# Creating edited headlines by replacing the tagged word in train[original] with edit\n",
        "\n",
        "train_set[\"new\"] = train_set.apply(lambda x:x[\"original\"].replace(x[\"original\"][x[\"original\"].find('<'):x[\"original\"].find(\">\")+1], x[\"edit\"]), axis=1)\n",
        "valid_set[\"new\"] = valid_set.apply(lambda x:x[\"original\"].replace(x[\"original\"][x[\"original\"].find('<'):x[\"original\"].find(\">\")+1], x[\"edit\"]), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "DZWWk8coxnhB",
        "outputId": "6b57b1a0-ad42-4fac-ac12-da82af181471"
      },
      "source": [
        "train_set[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined &lt;Isis/&gt; â€™ without trial in Iraq</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after &lt;Syria/&gt; strikes . What does that mean ?</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes &lt;Coalition/&gt;</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes party</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage/&gt; each other militarily</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>In an apparent first , Iran and Israel slap each other militarily</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vice/&gt; President .</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled school President .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8832</td>\n",
              "      <td>All 22 &lt;promises/&gt; Trump made in his speech to Congress , in one chart</td>\n",
              "      <td>sounds</td>\n",
              "      <td>22200</td>\n",
              "      <td>1.2</td>\n",
              "      <td>All 22 sounds Trump made in his speech to Congress , in one chart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12174</td>\n",
              "      <td>New DOJ alert system will flag &lt;crimes/&gt; against police</td>\n",
              "      <td>laughter</td>\n",
              "      <td>32100</td>\n",
              "      <td>1.2</td>\n",
              "      <td>New DOJ alert system will flag laughter against police</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3731</td>\n",
              "      <td>As Someone Who Grew Up Among Fundamentalist &lt;Christians/&gt; In The US , I 'm Surprised Anyone 's Surprised About Roy Moore</td>\n",
              "      <td>morons</td>\n",
              "      <td>21110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>As Someone Who Grew Up Among Fundamentalist morons In The US , I 'm Surprised Anyone 's Surprised About Roy Moore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6554</td>\n",
              "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their &lt;money/&gt;</td>\n",
              "      <td>loonies</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their loonies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>14191</td>\n",
              "      <td>Dutch minister resigns in drug baron &lt;row/&gt;</td>\n",
              "      <td>blow</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dutch minister resigns in drug baron blow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                                                                                                new\n",
              "0  14530  ...  France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq                                   \n",
              "1  13034  ...  Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ?                 \n",
              "2  8731   ...  Iceland PM Calls Snap Vote as Pedophile Furor Crashes party                                                      \n",
              "3  76     ...  In an apparent first , Iran and Israel slap each other militarily                                                \n",
              "4  6164   ...  Trump was told weeks ago that Flynn misled school President .                                                    \n",
              "5  8832   ...  All 22 sounds Trump made in his speech to Congress , in one chart                                                \n",
              "6  12174  ...  New DOJ alert system will flag laughter against police                                                           \n",
              "7  3731   ...  As Someone Who Grew Up Among Fundamentalist morons In The US , I 'm Surprised Anyone 's Surprised About Roy Moore\n",
              "8  6554   ...  Canadians may pay more taxes than Americans , but here 's what they get for their loonies                        \n",
              "9  14191  ...  Dutch minister resigns in drug baron blow                                                                        \n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt0CGh-RxzZt"
      },
      "source": [
        "# Creating a column containing the old words from the original sentence\n",
        "\n",
        "train_set[\"old_words\"] = train_set.apply(lambda x:x[\"original\"][x[\"original\"].find('<')+1:x[\"original\"].find('>')-1],axis=1)\n",
        "valid_set[\"old_words\"] = valid_set.apply(lambda x:x[\"original\"][x[\"original\"].find('<')+1:x[\"original\"].find('>')-1],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "-pAPTgP2yuPw",
        "outputId": "a7484b70-dd00-4579-c70e-a9ed17da1ef1"
      },
      "source": [
        "train_set[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>new</th>\n",
              "      <th>old_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined &lt;Isis/&gt; â€™ without trial in Iraq</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq</td>\n",
              "      <td>Isis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after &lt;Syria/&gt; strikes . What does that mean ?</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ?</td>\n",
              "      <td>Syria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes &lt;Coalition/&gt;</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes party</td>\n",
              "      <td>Coalition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage/&gt; each other militarily</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>In an apparent first , Iran and Israel slap each other militarily</td>\n",
              "      <td>engage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vice/&gt; President .</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled school President .</td>\n",
              "      <td>Vice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8832</td>\n",
              "      <td>All 22 &lt;promises/&gt; Trump made in his speech to Congress , in one chart</td>\n",
              "      <td>sounds</td>\n",
              "      <td>22200</td>\n",
              "      <td>1.2</td>\n",
              "      <td>All 22 sounds Trump made in his speech to Congress , in one chart</td>\n",
              "      <td>promises</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12174</td>\n",
              "      <td>New DOJ alert system will flag &lt;crimes/&gt; against police</td>\n",
              "      <td>laughter</td>\n",
              "      <td>32100</td>\n",
              "      <td>1.2</td>\n",
              "      <td>New DOJ alert system will flag laughter against police</td>\n",
              "      <td>crimes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3731</td>\n",
              "      <td>As Someone Who Grew Up Among Fundamentalist &lt;Christians/&gt; In The US , I 'm Surprised Anyone 's Surprised About Roy Moore</td>\n",
              "      <td>morons</td>\n",
              "      <td>21110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>As Someone Who Grew Up Among Fundamentalist morons In The US , I 'm Surprised Anyone 's Surprised About Roy Moore</td>\n",
              "      <td>Christians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6554</td>\n",
              "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their &lt;money/&gt;</td>\n",
              "      <td>loonies</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their loonies</td>\n",
              "      <td>money</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>14191</td>\n",
              "      <td>Dutch minister resigns in drug baron &lt;row/&gt;</td>\n",
              "      <td>blow</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dutch minister resigns in drug baron blow</td>\n",
              "      <td>row</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...   old_words\n",
              "0  14530  ...  Isis      \n",
              "1  13034  ...  Syria     \n",
              "2  8731   ...  Coalition \n",
              "3  76     ...  engage    \n",
              "4  6164   ...  Vice      \n",
              "5  8832   ...  promises  \n",
              "6  12174  ...  crimes    \n",
              "7  3731   ...  Christians\n",
              "8  6554   ...  money     \n",
              "9  14191  ...  row       \n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "OMHmCQ6ey4it",
        "outputId": "fa233cb6-32cf-44e4-bfcc-bf1ddb888389"
      },
      "source": [
        "valid_set[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>new</th>\n",
              "      <th>old_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted of long-abolished sexual offences are posthumously pardoned</td>\n",
              "      <td>swans</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands of gay and bisexual swans convicted of long-abolished sexual offences are posthumously pardoned</td>\n",
              "      <td>men</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12736</td>\n",
              "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
              "      <td>chef</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Special chef appointed to Trump Russia</td>\n",
              "      <td>prosecutor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12274</td>\n",
              "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror &lt;suspects/&gt;</td>\n",
              "      <td>squad</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror squad</td>\n",
              "      <td>suspects</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8823</td>\n",
              "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ' unfounded rumor ' about Melania Trump</td>\n",
              "      <td>applauds</td>\n",
              "      <td>32210</td>\n",
              "      <td>1.6</td>\n",
              "      <td>N.Y. Times applauds reporter for sharing ' unfounded rumor ' about Melania Trump</td>\n",
              "      <td>reprimands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5087</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Russian &lt;Missile/&gt; striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .</td>\n",
              "      <td>balloon</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Russian balloon striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .</td>\n",
              "      <td>Missile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13178</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murphy wins Democratic primary in bid to &lt;replace/&gt; New Jersey GOP Gov. Christie</td>\n",
              "      <td>chase</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murphy wins Democratic primary in bid to chase New Jersey GOP Gov. Christie</td>\n",
              "      <td>replace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11799</td>\n",
              "      <td>Trump â€™s next military &lt;scapegoat/&gt; : Foreign-born service members targeted by Pentagon</td>\n",
              "      <td>assassinations</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Trump â€™s next military assassinations : Foreign-born service members targeted by Pentagon</td>\n",
              "      <td>scapegoat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13425</td>\n",
              "      <td>President Trump â€™s Golden Age of &lt;Trolling/&gt;</td>\n",
              "      <td>Skydiving</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>President Trump â€™s Golden Age of Skydiving</td>\n",
              "      <td>Trolling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12497</td>\n",
              "      <td>US urges UN to &lt;punish/&gt; Iran , but Russia says no sanctions</td>\n",
              "      <td>tickle</td>\n",
              "      <td>21110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>US urges UN to tickle Iran , but Russia says no sanctions</td>\n",
              "      <td>punish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1185</td>\n",
              "      <td>Taliban &lt;kill/&gt; 95 with ambulance bomb</td>\n",
              "      <td>bores</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Taliban bores 95 with ambulance bomb</td>\n",
              "      <td>kill</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...   old_words\n",
              "0  1723   ...  men       \n",
              "1  12736  ...  prosecutor\n",
              "2  12274  ...  suspects  \n",
              "3  8823   ...  reprimands\n",
              "4  5087   ...  Missile   \n",
              "5  13178  ...  replace   \n",
              "6  11799  ...  scapegoat \n",
              "7  13425  ...  Trolling  \n",
              "8  12497  ...  punish    \n",
              "9  1185   ...  kill      \n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq_QK5YIy9JY"
      },
      "source": [
        "# Creating a column containing both the sentences seperated by [SEP] token, since humour is a relative quantity\n",
        "\n",
        "train_set[\"new_text\"] = train_set.apply(lambda x:x[\"new\"] + ' [SEP] From '+x[\"old_words\"] + ' to '+x[\"edit\"] ,axis=1)\n",
        "valid_set[\"new_text\"] = valid_set.apply(lambda x:x[\"new\"] + ' [SEP] From '+x[\"old_words\"] + ' to '+x[\"edit\"] ,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "hNXsLb54zd3o",
        "outputId": "51bdd94c-34e0-4064-8ddc-7d95587e9219"
      },
      "source": [
        "train_set[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>new</th>\n",
              "      <th>old_words</th>\n",
              "      <th>new_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14530</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined &lt;Isis/&gt; â€™ without trial in Iraq</td>\n",
              "      <td>twins</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq</td>\n",
              "      <td>Isis</td>\n",
              "      <td>France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq [SEP] From Isis to twins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13034</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after &lt;Syria/&gt; strikes . What does that mean ?</td>\n",
              "      <td>bowling</td>\n",
              "      <td>33110</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ?</td>\n",
              "      <td>Syria</td>\n",
              "      <td>Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ? [SEP] From Syria to bowling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8731</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes &lt;Coalition/&gt;</td>\n",
              "      <td>party</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes party</td>\n",
              "      <td>Coalition</td>\n",
              "      <td>Iceland PM Calls Snap Vote as Pedophile Furor Crashes party  [SEP] From Coalition to party</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>76</td>\n",
              "      <td>In an apparent first , Iran and Israel &lt;engage/&gt; each other militarily</td>\n",
              "      <td>slap</td>\n",
              "      <td>20000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>In an apparent first , Iran and Israel slap each other militarily</td>\n",
              "      <td>engage</td>\n",
              "      <td>In an apparent first , Iran and Israel slap each other militarily [SEP] From engage to slap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6164</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled &lt;Vice/&gt; President .</td>\n",
              "      <td>school</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled school President .</td>\n",
              "      <td>Vice</td>\n",
              "      <td>Trump was told weeks ago that Flynn misled school President . [SEP] From Vice to school</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8832</td>\n",
              "      <td>All 22 &lt;promises/&gt; Trump made in his speech to Congress , in one chart</td>\n",
              "      <td>sounds</td>\n",
              "      <td>22200</td>\n",
              "      <td>1.2</td>\n",
              "      <td>All 22 sounds Trump made in his speech to Congress , in one chart</td>\n",
              "      <td>promises</td>\n",
              "      <td>All 22 sounds Trump made in his speech to Congress , in one chart [SEP] From promises to sounds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12174</td>\n",
              "      <td>New DOJ alert system will flag &lt;crimes/&gt; against police</td>\n",
              "      <td>laughter</td>\n",
              "      <td>32100</td>\n",
              "      <td>1.2</td>\n",
              "      <td>New DOJ alert system will flag laughter against police</td>\n",
              "      <td>crimes</td>\n",
              "      <td>New DOJ alert system will flag laughter against police [SEP] From crimes to laughter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3731</td>\n",
              "      <td>As Someone Who Grew Up Among Fundamentalist &lt;Christians/&gt; In The US , I 'm Surprised Anyone 's Surprised About Roy Moore</td>\n",
              "      <td>morons</td>\n",
              "      <td>21110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>As Someone Who Grew Up Among Fundamentalist morons In The US , I 'm Surprised Anyone 's Surprised About Roy Moore</td>\n",
              "      <td>Christians</td>\n",
              "      <td>As Someone Who Grew Up Among Fundamentalist morons In The US , I 'm Surprised Anyone 's Surprised About Roy Moore [SEP] From Christians to morons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6554</td>\n",
              "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their &lt;money/&gt;</td>\n",
              "      <td>loonies</td>\n",
              "      <td>10000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their loonies</td>\n",
              "      <td>money</td>\n",
              "      <td>Canadians may pay more taxes than Americans , but here 's what they get for their loonies  [SEP] From money to loonies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>14191</td>\n",
              "      <td>Dutch minister resigns in drug baron &lt;row/&gt;</td>\n",
              "      <td>blow</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Dutch minister resigns in drug baron blow</td>\n",
              "      <td>row</td>\n",
              "      <td>Dutch minister resigns in drug baron blow  [SEP] From row to blow</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                                                                                                                           new_text\n",
              "0  14530  ...  France is â€˜ hunting down its citizens who joined twins â€™ without trial in Iraq [SEP] From Isis to twins                                          \n",
              "1  13034  ...  Pentagon claims 2,000 % increase in Russian trolls after bowling strikes . What does that mean ? [SEP] From Syria to bowling                     \n",
              "2  8731   ...  Iceland PM Calls Snap Vote as Pedophile Furor Crashes party  [SEP] From Coalition to party                                                       \n",
              "3  76     ...  In an apparent first , Iran and Israel slap each other militarily [SEP] From engage to slap                                                      \n",
              "4  6164   ...  Trump was told weeks ago that Flynn misled school President . [SEP] From Vice to school                                                          \n",
              "5  8832   ...  All 22 sounds Trump made in his speech to Congress , in one chart [SEP] From promises to sounds                                                  \n",
              "6  12174  ...  New DOJ alert system will flag laughter against police [SEP] From crimes to laughter                                                             \n",
              "7  3731   ...  As Someone Who Grew Up Among Fundamentalist morons In The US , I 'm Surprised Anyone 's Surprised About Roy Moore [SEP] From Christians to morons\n",
              "8  6554   ...  Canadians may pay more taxes than Americans , but here 's what they get for their loonies  [SEP] From money to loonies                           \n",
              "9  14191  ...  Dutch minister resigns in drug baron blow  [SEP] From row to blow                                                                                \n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "N66T8eRjzh4v",
        "outputId": "a5ce7196-8256-4eeb-9601-2223476b60cd"
      },
      "source": [
        "valid_set[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original</th>\n",
              "      <th>edit</th>\n",
              "      <th>grades</th>\n",
              "      <th>meanGrade</th>\n",
              "      <th>new</th>\n",
              "      <th>old_words</th>\n",
              "      <th>new_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1723</td>\n",
              "      <td>Thousands of gay and bisexual &lt;men/&gt; convicted of long-abolished sexual offences are posthumously pardoned</td>\n",
              "      <td>swans</td>\n",
              "      <td>22100</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands of gay and bisexual swans convicted of long-abolished sexual offences are posthumously pardoned</td>\n",
              "      <td>men</td>\n",
              "      <td>Thousands of gay and bisexual swans convicted of long-abolished sexual offences are posthumously pardoned [SEP] From men to swans</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12736</td>\n",
              "      <td>Special &lt;prosecutor/&gt; appointed to Trump Russia</td>\n",
              "      <td>chef</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Special chef appointed to Trump Russia</td>\n",
              "      <td>prosecutor</td>\n",
              "      <td>Special chef appointed to Trump Russia [SEP] From prosecutor to chef</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12274</td>\n",
              "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror &lt;suspects/&gt;</td>\n",
              "      <td>squad</td>\n",
              "      <td>21000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror squad</td>\n",
              "      <td>suspects</td>\n",
              "      <td>Spanish police detain man and search Ripoll addresses in hunt for terror squad  [SEP] From suspects to squad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8823</td>\n",
              "      <td>N.Y. Times &lt;reprimands/&gt; reporter for sharing ' unfounded rumor ' about Melania Trump</td>\n",
              "      <td>applauds</td>\n",
              "      <td>32210</td>\n",
              "      <td>1.6</td>\n",
              "      <td>N.Y. Times applauds reporter for sharing ' unfounded rumor ' about Melania Trump</td>\n",
              "      <td>reprimands</td>\n",
              "      <td>N.Y. Times applauds reporter for sharing ' unfounded rumor ' about Melania Trump [SEP] From reprimands to applauds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5087</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Russian &lt;Missile/&gt; striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .</td>\n",
              "      <td>balloon</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Russian balloon striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB .</td>\n",
              "      <td>Missile</td>\n",
              "      <td>Vladimir Putin Releases Video Simulation Of Russian balloon striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB . [SEP] From Missile to balloon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13178</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murphy wins Democratic primary in bid to &lt;replace/&gt; New Jersey GOP Gov. Christie</td>\n",
              "      <td>chase</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murphy wins Democratic primary in bid to chase New Jersey GOP Gov. Christie</td>\n",
              "      <td>replace</td>\n",
              "      <td>Ex-Goldman Sachs boss , Obama ambassador Murphy wins Democratic primary in bid to chase New Jersey GOP Gov. Christie [SEP] From replace to chase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11799</td>\n",
              "      <td>Trump â€™s next military &lt;scapegoat/&gt; : Foreign-born service members targeted by Pentagon</td>\n",
              "      <td>assassinations</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>Trump â€™s next military assassinations : Foreign-born service members targeted by Pentagon</td>\n",
              "      <td>scapegoat</td>\n",
              "      <td>Trump â€™s next military assassinations : Foreign-born service members targeted by Pentagon [SEP] From scapegoat to assassinations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13425</td>\n",
              "      <td>President Trump â€™s Golden Age of &lt;Trolling/&gt;</td>\n",
              "      <td>Skydiving</td>\n",
              "      <td>21100</td>\n",
              "      <td>0.8</td>\n",
              "      <td>President Trump â€™s Golden Age of Skydiving</td>\n",
              "      <td>Trolling</td>\n",
              "      <td>President Trump â€™s Golden Age of Skydiving  [SEP] From Trolling to Skydiving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12497</td>\n",
              "      <td>US urges UN to &lt;punish/&gt; Iran , but Russia says no sanctions</td>\n",
              "      <td>tickle</td>\n",
              "      <td>21110</td>\n",
              "      <td>1.0</td>\n",
              "      <td>US urges UN to tickle Iran , but Russia says no sanctions</td>\n",
              "      <td>punish</td>\n",
              "      <td>US urges UN to tickle Iran , but Russia says no sanctions [SEP] From punish to tickle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1185</td>\n",
              "      <td>Taliban &lt;kill/&gt; 95 with ambulance bomb</td>\n",
              "      <td>bores</td>\n",
              "      <td>11000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Taliban bores 95 with ambulance bomb</td>\n",
              "      <td>kill</td>\n",
              "      <td>Taliban bores 95 with ambulance bomb [SEP] From kill to bores</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                                                                                                                                                       new_text\n",
              "0  1723   ...  Thousands of gay and bisexual swans convicted of long-abolished sexual offences are posthumously pardoned [SEP] From men to swans                                            \n",
              "1  12736  ...  Special chef appointed to Trump Russia [SEP] From prosecutor to chef                                                                                                         \n",
              "2  12274  ...  Spanish police detain man and search Ripoll addresses in hunt for terror squad  [SEP] From suspects to squad                                                                 \n",
              "3  8823   ...  N.Y. Times applauds reporter for sharing ' unfounded rumor ' about Melania Trump [SEP] From reprimands to applauds                                                           \n",
              "4  5087   ...  Vladimir Putin Releases Video Simulation Of Russian balloon striking Florida conveniently right on top of USSOCOM headquarters at MacDill AFB . [SEP] From Missile to balloon\n",
              "5  13178  ...  Ex-Goldman Sachs boss , Obama ambassador Murphy wins Democratic primary in bid to chase New Jersey GOP Gov. Christie [SEP] From replace to chase                             \n",
              "6  11799  ...  Trump â€™s next military assassinations : Foreign-born service members targeted by Pentagon [SEP] From scapegoat to assassinations                                             \n",
              "7  13425  ...  President Trump â€™s Golden Age of Skydiving  [SEP] From Trolling to Skydiving                                                                                                 \n",
              "8  12497  ...  US urges UN to tickle Iran , but Russia says no sanctions [SEP] From punish to tickle                                                                                        \n",
              "9  1185   ...  Taliban bores 95 with ambulance bomb [SEP] From kill to bores                                                                                                                \n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6lUwfx6zkkj"
      },
      "source": [
        "## Tokenizing and Formatting data according to BERT standards"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_fQ9heF05zX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "abdad9397fe342c881f3326133586b94",
            "f4fa26d7460747a2b776cef6d3e05319",
            "ed8a4193ed044238bc8fac21ce524962",
            "7b084906c5c64763b0f6be9880fbc41f",
            "8e1efe71b16f419a8fe21370de638332",
            "173e94a6727e47a69a547d556ec435d8",
            "f672f6ff2d094a01914f53dcba368659",
            "c3a22fd324d8439ebf1d35e3e669a205",
            "d322eddf22ac4b7181334df17d9b7721",
            "5547aaa8122341b4a8bc269095cb7503",
            "87f4b414439f4f7ea48e9163c5083929",
            "04902f1363e44fcd843473a16042223c",
            "4ff1fceee0fe4f7594c4b76d91592f24",
            "f679382fda674304a47a18771aa25a66",
            "84859d3106564496b69e7e1cc0fb668a",
            "99b438cd4fbb4515a870d71ebc9758fd",
            "5b0f5c342db340df947b566cda487c5c",
            "fb6d950fb3cb4c4eb71c7f2969adeeb8",
            "1bbc07e579ef4768aab8affa53436c5f",
            "1511d11cc9464f0b94a50773bae0c320",
            "ede23482ba4e495fbed511e92cea10d7",
            "08385086c0b44a70903a6b767f110c34",
            "4946afc0f789418dabab4ca1a9b70c8e",
            "8b980c49e7ed41c796e9badc4a38d8e8"
          ]
        },
        "outputId": "a3a315e3-8fc5-413d-dc06-872b8836dd31"
      },
      "source": [
        "# Loading Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abdad9397fe342c881f3326133586b94",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d322eddf22ac4b7181334df17d9b7721",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b0f5c342db340df947b566cda487c5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2P2EnTU2twB"
      },
      "source": [
        "# Train data\n",
        "# Getting original sentences and their labels and combining data with [SEP] tokens in between and [CLS] at start\n",
        "# Truncating max length to be of 32 and creating attention masks and converting the data into pytorch tensors\n",
        "\n",
        "sentences = train_set[\"new_text\"].values\n",
        "labels = train_set[\"meanGrade\"].values\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in sentences:\n",
        "\n",
        "    # encoding a sentence\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,  # [CLS] and [SEP]\n",
        "                        truncation=True,\n",
        "                        max_length = 32,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = \"pt\"  # PyTorch Tensors\n",
        "                    )\n",
        "    \n",
        "    # adding an encoded sentence to the list\n",
        "    input_ids.append(encoded_dict[\"input_ids\"])\n",
        "\n",
        "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKm1R8jx2-J8",
        "outputId": "f46d4dd7-3eee-407b-e815-65136e5449a2"
      },
      "source": [
        "input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  2605,  2003,  ...,     0,     0,     0],\n",
              "        [  101, 20864,  4447,  ...,     0,     0,     0],\n",
              "        [  101, 10399,  7610,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  8592,  2240,  ...,     0,     0,     0],\n",
              "        [  101,  3996,  2610,  ...,     0,     0,     0],\n",
              "        [  101,  2182,  1005,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMM7ZILz6CyX",
        "outputId": "16d2567d-3df0-4d72-debd-ea60baf8c48c"
      },
      "source": [
        "attention_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyFB-4-D6EeS"
      },
      "source": [
        "# Validation data\n",
        "# Doing the above steps for validation data\n",
        "\n",
        "sentences_valid = valid_set[\"new_text\"].values\n",
        "labels_valid = valid_set[\"meanGrade\"].values\n",
        "\n",
        "input_ids_valid = []\n",
        "attention_masks_valid = []\n",
        "\n",
        "for sent in sentences_valid:\n",
        "\n",
        "    # encoding a sentence\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,  # [CLS] and [SEP]\n",
        "                        truncation=True,\n",
        "                        max_length = 32,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = \"pt\"  # PyTorch Tensors\n",
        "                    )\n",
        "    \n",
        "    # adding an encoded sentence to the list\n",
        "    input_ids_valid.append(encoded_dict[\"input_ids\"])\n",
        "\n",
        "    attention_masks_valid.append(encoded_dict[\"attention_mask\"])\n",
        "\n",
        "input_ids_valid = torch.cat(input_ids_valid, dim=0)\n",
        "attention_masks_valid = torch.cat(attention_masks_valid, dim=0)\n",
        "\n",
        "labels_valid = torch.tensor(labels_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-J67GSR6xK7",
        "outputId": "72957575-ffc1-4f0c-cee1-a4885fd44110"
      },
      "source": [
        "input_ids_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  5190,  1997,  ...,     0,     0,     0],\n",
              "        [  101,  2569, 10026,  ...,     0,     0,     0],\n",
              "        [  101,  3009,  2610,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  2149,  2231,  ...,     0,     0,     0],\n",
              "        [  101, 25597, 18353,  ...,     0,     0,     0],\n",
              "        [  101,  1999,  3945,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8PElr1P618U",
        "outputId": "bdc25b89-bd6e-41e6-8dac-be86e17ea37b"
      },
      "source": [
        "attention_masks_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsrk8tF63yP"
      },
      "source": [
        "## Creating DataLoaders for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU9pGvWM6-HM"
      },
      "source": [
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "valid_dataset = TensorDataset(input_ids_valid, attention_masks_valid, labels_valid)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                sampler = RandomSampler(train_dataset),\n",
        "                batch_size = batch_size\n",
        "            )\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "                valid_dataset,\n",
        "                sampler = SequentialSampler(valid_dataset),\n",
        "                batch_size = batch_size\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtpW7IXM8C9u"
      },
      "source": [
        "# Modelling, basically Fine-Tuning BERT for this task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRpQvnJb8Ke8"
      },
      "source": [
        "## Defining our BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d58909ec818e43b7ac68b782908831ec",
            "8240d92612664f34a41d2ef22b902ae4",
            "ade15b632c734065a8ee81af0f061d2c",
            "540f7c56aaaa49969334476aee76a63f",
            "1ce6a9cb19fe4697abe5dbf843c64640",
            "d92b795696d54e569152af52b8b9ea21",
            "b73b344e1b5a425cb44c849470dab50a",
            "563785ff2d3e40bfbb1ed0b01b52cda7",
            "55f5f6c28b2b4516a90b98f3579bd5b4",
            "08d2d0a690324eadb5c87b1e1f53ceea",
            "9e3f4b0858294143819eb9892ed3bf9d",
            "1f2b704a16da42ac8a3aa10dcb870933",
            "c6f5e4c6e9f04e5780777486d4a6b794",
            "2fb28545a25e47a3b989c0225c6cd9a4",
            "238130fdb0ad40d0961df55b3e4321b4",
            "e88dab3c732747649aa711e526c9b32b"
          ]
        },
        "id": "V-EH9_L68O_M",
        "outputId": "c5a5676e-095f-4686-fa97-25d5a1cfc480"
      },
      "source": [
        "# We'll use BertForSequenceClassification model and we'll set the number of classes equal to 1, which will make it work as regressor\n",
        "# We'll use the normal uncased, base version of BERT model which has 12 layers\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels = 1,\n",
        "        output_attentions = False,\n",
        "        output_hidden_states = False,\n",
        "        return_dict=False\n",
        "    )\n",
        "\n",
        "# Moving model on to the GPU\n",
        "model.cuda()\n",
        "\n",
        "# To work on double type values\n",
        "model.double()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d58909ec818e43b7ac68b782908831ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55f5f6c28b2b4516a90b98f3579bd5b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk7zeiqL-LMn"
      },
      "source": [
        "## Defining training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdtRfAHl-fUM"
      },
      "source": [
        "# Adam Algorithm with Weight Decay\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 9e-6,\n",
        "                  eps = 1e-8)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_warmup_steps = 0,\n",
        "                num_training_steps = total_steps\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwmHq051_iQK"
      },
      "source": [
        "## Defining training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ1e-blX_ya3",
        "outputId": "19960661-795a-46ea-8631-653bf4aea192"
      },
      "source": [
        "# Standard training code used for training and fine-tuning neural networks in PyTorch \n",
        "\n",
        "seed_value = 99\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "training_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"------------- Epoch {e+1} / {epochs} ----------------\")\n",
        "    print(\"Training........\")\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Training mode\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        # Unpacking data from loader and moving to gpu\n",
        "        input_ids = batch[0].cuda()\n",
        "        attention_masks = batch[1].cuda()\n",
        "        labels = batch[2].cuda()\n",
        "\n",
        "        # Clearing previous gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Doing a forward pass\n",
        "        loss, logits = model(\n",
        "                             input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = attention_masks,\n",
        "                             labels = labels\n",
        "                         )\n",
        "        \n",
        "        # Accumulating training loss over all batches to calculate average later\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Calculating gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to deal with exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Updating gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Updating learning rate with scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"..... Average training loss: {avg_train_loss:.2f} ......\")\n",
        "\n",
        "    print(\"\\nValidation........\")\n",
        "\n",
        "    # Evaluation Phase\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    y_pred = np.array([])\n",
        "    y_true = np.array([])\n",
        "\n",
        "    for batch in valid_loader:\n",
        "\n",
        "        input_ids = batch[0].cuda()\n",
        "        attention_masks = batch[1].cuda()\n",
        "        labels = batch[2].cuda()\n",
        "\n",
        "        # No gradients to be calculated\n",
        "        with torch.no_grad():\n",
        "\n",
        "            loss, logits = model(\n",
        "                             input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = attention_masks,\n",
        "                             labels = labels\n",
        "                         )\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Moving logits and labels to cpu\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "        y_pred = np.append(y_pred,logits)\n",
        "        y_true = np.append(y_true,label_ids)\n",
        "\n",
        "    # Using RMSE as our evaluation metric, since it is a regression task\n",
        "    rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)\n",
        "    print(f\"---- RMSE: {rmse:.4f} ----\")\n",
        "\n",
        "    # Calculate average loss over all the batches\n",
        "    avg_val_loss = total_eval_loss / len(valid_loader)\n",
        "\n",
        "    print(f\"..... Average validation loss: {avg_val_loss:.2f} ......\")\n",
        "\n",
        "    training_history.append(\n",
        "        {\n",
        "            \"epoch\": e+1,\n",
        "            \"Training Loss\": avg_train_loss,\n",
        "            \"Validation Loss\": avg_val_loss,\n",
        "            \"RMSE\": rmse,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\\n Training Finished!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------- Epoch 1 / 5 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.36 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5785 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 2 / 5 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.35 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5795 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 3 / 5 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5786 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 4 / 5 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5780 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 5 / 5 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5781 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            " Training Finished!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0btd2Jm4rvZK"
      },
      "source": [
        "Training 5 epochs took around an hour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvNkilcoHYKY"
      },
      "source": [
        "## Tuning Hyperparameters for better results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK1VjxLjVxvE"
      },
      "source": [
        "# Adam Algorithm with Weight Decay\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8)\n",
        "\n",
        "epochs = 10\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_warmup_steps = 0,\n",
        "                num_training_steps = total_steps\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq0qECTsV67n",
        "outputId": "be361b6d-b238-424c-d940-f3de2a9532c3"
      },
      "source": [
        "# Standard training code used for training and fine-tuning neural networks in PyTorch \n",
        "\n",
        "seed_value = 99\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "training_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"------------- Epoch {e+1} / {epochs} ----------------\")\n",
        "    print(\"Training........\")\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Training mode\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        # Unpacking data from loader and moving to gpu\n",
        "        input_ids = batch[0].cuda()\n",
        "        attention_masks = batch[1].cuda()\n",
        "        labels = batch[2].cuda()\n",
        "\n",
        "        # Clearing previous gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Doing a forward pass\n",
        "        loss, logits = model(\n",
        "                             input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = attention_masks,\n",
        "                             labels = labels\n",
        "                         )\n",
        "        \n",
        "        # Accumulating training loss over all batches to calculate average later\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Calculating gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to deal with exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Updating gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Updating learning rate with scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"..... Average training loss: {avg_train_loss:.2f} ......\")\n",
        "\n",
        "    print(\"\\nValidation........\")\n",
        "\n",
        "    # Evaluation Phase\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    y_pred = np.array([])\n",
        "    y_true = np.array([])\n",
        "\n",
        "    for batch in valid_loader:\n",
        "\n",
        "        input_ids = batch[0].cuda()\n",
        "        attention_masks = batch[1].cuda()\n",
        "        labels = batch[2].cuda()\n",
        "\n",
        "        # No gradients to be calculated\n",
        "        with torch.no_grad():\n",
        "\n",
        "            loss, logits = model(\n",
        "                             input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = attention_masks,\n",
        "                             labels = labels\n",
        "                         )\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Moving logits and labels to cpu\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "        y_pred = np.append(y_pred,logits)\n",
        "        y_true = np.append(y_true,label_ids)\n",
        "\n",
        "    # Using RMSE as our evaluation metric, since it is a regression task\n",
        "    rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)\n",
        "    print(f\"---- RMSE: {rmse:.4f} ----\")\n",
        "\n",
        "    # Calculate average loss over all the batches\n",
        "    avg_val_loss = total_eval_loss / len(valid_loader)\n",
        "\n",
        "    print(f\"..... Average validation loss: {avg_val_loss:.2f} ......\")\n",
        "\n",
        "    training_history.append(\n",
        "        {\n",
        "            \"epoch\": e+1,\n",
        "            \"Training Loss\": avg_train_loss,\n",
        "            \"Validation Loss\": avg_val_loss,\n",
        "            \"RMSE\": rmse,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\\n Training Finished!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------- Epoch 1 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.36 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5791 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 2 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5788 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 3 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5781 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 4 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5786 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 5 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5786 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 6 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5798 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 7 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5793 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 8 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5798 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 9 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5782 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 10 / 10 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.34 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5782 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            " Training Finished!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrYjHZ2XxOmo"
      },
      "source": [
        "Training for 10 epochs took more than 2 hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWd7zl_ayVSv"
      },
      "source": [
        "# Adam Algorithm with Weight Decay\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 9e-4,\n",
        "                  eps = 1e-6)\n",
        "\n",
        "epochs = 7\n",
        "\n",
        "total_steps = len(train_loader) * epochs\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer,\n",
        "                num_warmup_steps = 0,\n",
        "                num_training_steps = total_steps\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHyUlKqAKP08",
        "outputId": "d85000c7-a514-46b1-cd60-1a6b23b3cecc"
      },
      "source": [
        "# Standard training code used for training and fine-tuning neural networks in PyTorch \n",
        "\n",
        "seed_value = 99\n",
        "\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "training_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"------------- Epoch {e+1} / {epochs} ----------------\")\n",
        "    print(\"Training........\")\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Training mode\n",
        "    model.train()\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "\n",
        "        # Unpacking data from loader and moving to gpu\n",
        "        input_ids = batch[0].cuda()\n",
        "        attention_masks = batch[1].cuda()\n",
        "        labels = batch[2].cuda()\n",
        "\n",
        "        # Clearing previous gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Doing a forward pass\n",
        "        loss, logits = model(\n",
        "                             input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = attention_masks,\n",
        "                             labels = labels\n",
        "                         )\n",
        "        \n",
        "        # Accumulating training loss over all batches to calculate average later\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Calculating gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to deal with exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Updating gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Updating learning rate with scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"..... Average training loss: {avg_train_loss:.2f} ......\")\n",
        "\n",
        "    print(\"\\nValidation........\")\n",
        "\n",
        "    # Evaluation Phase\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    y_pred = np.array([])\n",
        "    y_true = np.array([])\n",
        "\n",
        "    for batch in valid_loader:\n",
        "\n",
        "        input_ids = batch[0].cuda()\n",
        "        attention_masks = batch[1].cuda()\n",
        "        labels = batch[2].cuda()\n",
        "\n",
        "        # No gradients to be calculated\n",
        "        with torch.no_grad():\n",
        "\n",
        "            loss, logits = model(\n",
        "                             input_ids,\n",
        "                             token_type_ids = None,\n",
        "                             attention_mask = attention_masks,\n",
        "                             labels = labels\n",
        "                         )\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Moving logits and labels to cpu\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "        y_pred = np.append(y_pred,logits)\n",
        "        y_true = np.append(y_true,label_ids)\n",
        "\n",
        "    # Using RMSE as our evaluation metric, since it is a regression task\n",
        "    rmse = mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False)\n",
        "    print(f\"---- RMSE: {rmse:.4f} ----\")\n",
        "\n",
        "    # Calculate average loss over all the batches\n",
        "    avg_val_loss = total_eval_loss / len(valid_loader)\n",
        "\n",
        "    print(f\"..... Average validation loss: {avg_val_loss:.2f} ......\")\n",
        "\n",
        "    training_history.append(\n",
        "        {\n",
        "            \"epoch\": e+1,\n",
        "            \"Training Loss\": avg_train_loss,\n",
        "            \"Validation Loss\": avg_val_loss,\n",
        "            \"RMSE\": rmse,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\\n Training Finished!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------- Epoch 1 / 7 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.43 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5817 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 2 / 7 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.39 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.6045 ----\n",
            "..... Average validation loss: 0.37 ......\n",
            "\n",
            "------------- Epoch 3 / 7 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.37 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5788 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 4 / 7 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.36 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5834 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 5 / 7 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.36 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5789 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 6 / 7 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.35 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5829 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            "------------- Epoch 7 / 7 ----------------\n",
            "Training........\n",
            "\n",
            "..... Average training loss: 0.35 ......\n",
            "\n",
            "Validation........\n",
            "---- RMSE: 0.5788 ----\n",
            "..... Average validation loss: 0.34 ......\n",
            "\n",
            " Training Finished!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yoirla3dWBqY"
      },
      "source": [
        "Even after tuning parameters multiple times and training the models on those prameters the RMSE doesn't seem to decrease."
      ]
    }
  ]
}